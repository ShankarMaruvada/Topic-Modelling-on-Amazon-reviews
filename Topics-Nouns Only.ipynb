{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nouns only Topic Modelling\n",
    "   This script identifies various topics in the reviews, by filetring out only the nouns in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/maruv/Desktop/DSB/LDA/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data\n",
    "     This piece of code unzips the package and parses the json document as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.stats import itemfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_reviews = getDF(data_dir+'reviews_Cell_Phones_and_Accessories_5.json.gz')\n",
    "df_metadata = getDF(data_dir+'meta_Cell_Phones_and_Accessories.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Extract Nouns\n",
    "    By using the pos tagger in the NLTK we can extract the nouns from a given sentence/ review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk as nt\n",
    "noun_tags = [\"NN\",\"NNP\",\"NNS\",\"POS\",\"WP\"] #\"PRP$\" , \"PRP\", removing proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tags(sentence):\n",
    "    array_words = nt.word_tokenize(sentence)\n",
    "    tags = nt.pos_tag(array_words)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noun_words(review):\n",
    "    nouns =[];\n",
    "    all_tuples = tags(review)\n",
    "    for one in all_tuples:\n",
    "        for each in noun_tags:\n",
    "            if(each == one[1]):\n",
    "                nouns.append(one[0])\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forming a new data frame for the reviews of a selected items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59707</th>\n",
       "      <td>excellent product at 1/2 the price as sale at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59708</th>\n",
       "      <td>Sometimes the flap over the charging place is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59709</th>\n",
       "      <td>Great case.  Fits like every other Otterbox De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59710</th>\n",
       "      <td>Use these for our technicians and anyone that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59711</th>\n",
       "      <td>It's very strong and protects my 4S phone! I t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText\n",
       "59707  excellent product at 1/2 the price as sale at ...\n",
       "59708  Sometimes the flap over the charging place is ...\n",
       "59709  Great case.  Fits like every other Otterbox De...\n",
       "59710  Use these for our technicians and anyone that ...\n",
       "59711  It's very strong and protects my 4S phone! I t..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Creating a dataframe of items with required item reviews'''\n",
    "max_reviewed_item = df_reviews.loc[df_reviews.asin.isin(['B005SUHPO6']),['reviewText']]\n",
    "max_reviewed_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_max_corp = max_reviewed_item['reviewText']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting only Nouns and various forms of nouns\n",
    "Nouns were extracted, and proper nouns are not considered (I,we , them, they, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_nouns = []\n",
    "for each in final_max_corp:\n",
    "    total_nouns.append(noun_words(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, ['product', 'price', 'sale', 'store', 'fit', 'perfect', 'iphone'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_nouns),total_nouns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already have cleaned Matrix, we are not using nltk funtions to remove stop words or punctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Doc Term Matrix\n",
    "\n",
    "This piece of code creates a document term matrix that can further be used to build LDA models.\n",
    "\n",
    "Testing for complete reviews on the same item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Creating the term dictionary of our corpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(total_nouns)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_max_term_matrix = [dictionary.doc2bow(doc) for doc in total_nouns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Building Topics using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_max_term_matrix, num_topics=5, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.015*\"OtterBox\" + 0.008*\"Series\" + 0.007*\"one\"'), (1, '0.062*\"case\" + 0.026*\"Otterbox\" + 0.024*\"phone\"'), (2, '0.053*\"phone\" + 0.041*\"case\" + 0.035*\"iPhone\"'), (3, '0.067*\"phone\" + 0.067*\"case\" + 0.016*\"cases\"'), (4, '0.084*\"case\" + 0.063*\"phone\" + 0.021*\"screen\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=5, num_words=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
